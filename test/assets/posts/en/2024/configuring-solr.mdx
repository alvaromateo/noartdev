<div>
    <section id='post-intro'>
        # Configuring Solr
        <PublishDate year={2024} month={10} day={26}/>
        <Tags list={['development', 'solr', 'search']}/>
        <Summary>
            In this post I will show how to configure 
            <Link href='https://solr.apache.org/'>Solr</Link> to use it as search engine for a blog
            website.
        </Summary>
        <ContentTable/>
    </section>
    <section id='post-content'>

        In this previous <Link href='/blog/installing-solr'>article</Link> I explained how to install 
        <Link href='https://solr.apache.org/'>Solr</Link> using 
        <Link href='https://docs.docker.com/compose/gettingstarted/'>Docker Compose</Link> to be 
        able to use it as search engine for a blog website. Then I explained which features I wanted 
        for the search and I decided on a <Link href='/blog/planning-search'>general plan</Link> to get 
        there. Now I'm going to explain how I configured Solr to power the search of 
        <Link href='/home'>this website</Link>.

        Solr has several files that are used to configure its functionality. They are located 
        inside the Solr home directory, which inside the Docker instance is located at 
        */var/solr/data* and has the following structure.

        <CodeBlock language='text'>
{`/var/solr/data/
    solr.xml
    core_name/
        core.properties
        conf/
            solrconfig.xml
            managed-schema.xml
        data/
`}
        </CodeBlock>

        If you followed the article I did on <Link href='/blog/installing-solr'>how to install Solr</Link> 
        you should already have the *conf/* files ready to be edited, so let's dive in!

        ## solr.xml

        This file goes directly inside the Solr home directory and specifies the configuration 
        for the server instance. I have no need for this file as all the defaults are 
        enough (for now at least).

        ## Core configuration

        A core in Solr is the same as an index. It contains all the necessary files for indexing the collection, 
        a transaction log, and the configuration for the index. One can configure different 
        cores to create indexes that search through different types of documents or over the same 
        documents but in different ways.
        
        I only need a core/index for searching through all the blog posts. 
        The core has 2 main configuration files, located in the structure specified above.

        ### core.properties

        The core.properties file is used to configure simple core properties. It is created automatically 
        during Solr's <Link href='/blog/installing-solr'>installation</Link>.

        ### solrconfig.xml

        To configure the *solrconfig.xml* I took the default configuration file provided by Solr.
        Inside the docker container of Solr it can be found at */opt/solr/server/solr/configsets/_default*. 
        The file is very well documented, so it's easy to read and understand what each part does. 
        Most of the default configuration can be left as is. I will mention here the parts that I decided 
        to change.

        The <CodeBlock language='xml' inline>\<updateHandler\></CodeBlock> manages how the index updates are 
        done and it may affect performance. When I add a document to Solr, it is not searchable until it 
        is commited. While Solr makes its writes it can slow down, which might affect performance. Too 
        many commits and it will be slower, but too few and it might not find the latest data. In the case 
        of this blog, the searchable data are the posts - these are known and published at build time, so 
        I don't have to worry about commiting too often.
        
        Another distinction is that between *hard commit* and *soft commit*. A hard commit makes sure that 
        the index files have been flushed to stable storage and opens a new transaction log (rolling window 
        of updates since the last hard commit that help with data recovery if there is any crash and updates 
        that have not been commited). A soft commit is faster because it only makes the index changes visible 
        without writing any file. In the case of just a commit after a blog post has been publish I can deal 
        with only hard commits.
        
        To takes care of these use cases, I deleted the 
        <CodeBlock language='xml' inline>\<autoSoftCommit\></CodeBlock> configuration and left the following 
        options for committing automatically:

        <CodeBlock language='xml'>
{`<autoCommit>
    <maxTime>\${solr.autoCommit.maxTime:15000}</maxTime>
    <openSearcher>false</openSearcher>
</autoCommit>
`}
        </CodeBlock>

        #### Cache warming

        Solr uses caches to improve performance. These are cleared after a commit and they need to be 
        repopulated before being useful. To do this, caches can be "warmed" by populating the cache with 
        values from a previous cache. All settings related to caching can be controlled in the 
        <CodeBlock language='xml' inline>\<query\></CodeBlock> section. I left it as is by default, as the 
        caches size is set to 512 documents, which is far larger than the posts I have (for now...).

        TODO: set up the queries to warm up the cache

        #### Request handlers

        The next sections are the request handlers that respond to the queries/updates sent to Solr and 
        the *search components*. The request handlers can use defined search components to perform extra 
        actions like spell checking. I removed all the request handlers and search components to start with 
        a blank slate.

        

        #### Update Request Processors

        Last but not least there are the *Update Request Processors (URP)* - the search components equivalent 
        but for update requests. Every update runs through a chain of URPs.

        TODO: configure update request processors, request handlers and search components

        ### managed-schema.xml

        This file declares all the document fields and how they are analyzed. I decided to declare the 
        following types for each post/document that I will send to Solr to index.
        - url
        - title
        - date
        - tags
        - summary
        - sections (for the subtitles)
        - text
        - code

        todo

        ## Conclusion

        TODO

        Until next time!

    </section>
</div>